{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train[..., tf.newaxis], x_test[..., tf.newaxis]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna hyperparameters optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_model(x_train, y_train):\n",
    "    def objective(trial):\n",
    "        # Define the hyperparameters to optimize\n",
    "        num_filters = trial.suggest_int('num_filters', 16, 128)\n",
    "        kernel_size = trial.suggest_int('kernel_size', 3, 5)\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'sigmoid'])\n",
    "        \n",
    "        # Create the model with the specified hyperparameters\n",
    "        model = basemodel(num_filters, kernel_size, activation)\n",
    "        \n",
    "        # Compile the model with an Adam optimizer and a categorical cross-entropy loss function\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model on the training data, using a validation split\n",
    "        history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
    "        \n",
    "        # Extract the validation accuracy from the training history\n",
    "        val_acc = history.history['val_accuracy'][-1]\n",
    "        \n",
    "        return val_acc\n",
    "    \n",
    "    # Create a new study and run the optimization\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    \n",
    "    # Extract the best hyperparameters from the optimization\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # Create and return the best model based on the optimized hyperparameters\n",
    "    return basemodel(best_params['num_filters'], best_params['kernel_size'], best_params['activation'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a callback to save the model's weights after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'mnist_cnn.ckpt'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the training data, using a validation split and the checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = basemodel.fit(x_train, y_train, epochs=10, validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation accuracy over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
